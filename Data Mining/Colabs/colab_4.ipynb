{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# CS483 - Colab 4\n",
        "## Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "qcTbH0d9e0Nf",
        "outputId": "2dbef9fe-7d6a-44b8-d4e8-50136693c8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab 4 Mascot\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://media4.giphy.com/media/wtdVYmaRWJ1PyPcc8e/giphy.gif?cid=ecf05e478jdbzo92b89f2b5ud5184xda9cen1xce4bwmjeyu&ep=v1_stickers_search&rid=giphy.gif&ct=s\" width=\"150\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "print(\"Colab 4 Mascot\")\n",
        "Image(url='https://media4.giphy.com/media/wtdVYmaRWJ1PyPcc8e/giphy.gif?cid=ecf05e478jdbzo92b89f2b5ud5184xda9cen1xce4bwmjeyu&ep=v1_stickers_search&rid=giphy.gif&ct=s',width=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's set up Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-qHai2252mI",
        "outputId": "d1d1d691-576f-4104-abd0-3adc0939eb0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=a57b36169933ddfec17ad1cff98dba5dd9a5e34751799e87bf4d63cf90f6d03b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 39.6 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 123621 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u422-b05-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u422-b05-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUjUvXe3Sjk"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the files we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRElWs_x2mGh",
        "outputId": "9f567d0d-74b0-458f-df80-efa15d302361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QHsFTGUy2n1c"
      },
      "outputs": [],
      "source": [
        "id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.training')\n",
        "\n",
        "id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.test')\n",
        "\n",
        "id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.item')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n",
        "\n",
        "Next, we import some of the common libraries needed for our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrJlMBt1Ela"
      },
      "source": [
        "Let's initialize the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vm3sAVeK1EDZ"
      },
      "outputs": [],
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXdMR6wnEIM"
      },
      "source": [
        "In this Colab, we will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n",
        "\n",
        "We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "outputs": [],
      "source": [
        "schema_ratings = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), False),\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"rating\", IntegerType(), False),\n",
        "    StructField(\"timestamp\", IntegerType(), False)])\n",
        "\n",
        "schema_items = StructType([\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"movie\", StringType(), False)])\n",
        "\n",
        "training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n",
        "test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n",
        "items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MC_m1oygCoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3baa8e2-7513-4649-eb51-82dcaa801502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "81Vgo4ovCqtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881c9845-e293-4e9a-d65a-3bb5a14cf669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- movie: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "items.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "HPxrgaFqMD4H",
        "outputId": "31119bb4-4d9b-4a78-ea51-ba9aa29a97e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9w2aUvJ7KN"
      },
      "source": [
        "Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8XZaH16t_CIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19be5476-9709-4e72-816a-df3bc2ffc34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ratings in the training dataset: 80000\n",
            "Number of ratings in the test dataset: 20000\n",
            "Number of movies in the dataset: 1682\n"
          ]
        }
      ],
      "source": [
        "''' 3 lines of code in total expected.\n",
        "For sub-parts of the question (if any), creating different cells of code would be recommended.'''\n",
        "num_ratings_training = training.count()\n",
        "print(f\"Number of ratings in the training dataset: {num_ratings_training}\")\n",
        "num_ratings_test = test.count()\n",
        "print(f\"Number of ratings in the test dataset: {num_ratings_test}\")\n",
        "num_movies = items.count()\n",
        "print(f\"Number of movies in the dataset: {num_movies}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsaYOqRxar2"
      },
      "source": [
        "Using the training set, train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Oitav_xhQD9w"
      },
      "outputs": [],
      "source": [
        "''' 5-6 lines of code in total expected but can differ based on your style.\n",
        "For sub-parts of the question (if any), creating different cells of code would be recommended.'''\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "\n",
        "model = als.fit(training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtR1xRvonxiO"
      },
      "source": [
        "Now compute the RMSE on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GP23Xkgwi0SD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89f33fd-45eb-4296-db0e-8c48e431f69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 1.1266837287928624\n"
          ]
        }
      ],
      "source": [
        "''' 4-5 lines of code in total expected but can differ based on your style.\n",
        "For sub-parts of the question (if any), creating different cells of code would be recommended.'''\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "predictions = model.transform(test)\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBvSaWGEMHXI"
      },
      "source": [
        "At this point, you can use the trained model to produce the top-K recommendations for each user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KbMlWL5_UfSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb6b18d-7a9d-4251-eeb7-77d22e7e22b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|user_id|recommended_movies                                                                                                                                                                                                                                                                                                                 |\n",
            "+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1      |[Naked (1993), Radioland Murders (1994), Schizopolis (1996), Pather Panchali (1955), Double vie de V�ronique, La (Double Life of Veronique, The) (1991), Beautiful Thing (1996), Shooting Fish (1997), Ruby in Paradise (1993), City of Lost Children, The (1995), Incognito (1997)]                                               |\n",
            "|2      |[Love & Human Remains (1993), Live Nude Girls (1995), Women, The (1939), Ma vie en rose (My Life in Pink) (1997), Safe (1995), Addiction, The (1995), Cats Don't Dance (1997), Drunks (1995), Loaded (1994), Wild America (1997)]                                                                                                  |\n",
            "|3      |[Gridlock'd (1997), Foxfire (1996), One Night Stand (1997), Braindead (1992), Houseguest (1994), Top Hat (1935), Miami Rhapsody (1995), Kull the Conqueror (1997), Get on the Bus (1996), Whole Wide World, The (1996)]                                                                                                            |\n",
            "|4      |[Maximum Risk (1996), Beyond Rangoon (1995), Live Nude Girls (1995), Bad Taste (1987), Ruby in Paradise (1993), Underneath, The (1995), Braindead (1992), Top Hat (1935), Mina Tannenbaum (1994), Fallen (1998)]                                                                                                                   |\n",
            "|5      |[Ruby in Paradise (1993), Naked (1993), I'll Do Anything (1994), Carpool (1996), Dracula: Dead and Loving It (1995), Love & Human Remains (1993), Little Lord Fauntleroy (1936), Romeo Is Bleeding (1993), Love and a .45 (1994), Bhaji on the Beach (1993)]                                                                       |\n",
            "|6      |[Angel Baby (1995), Ace Ventura: When Nature Calls (1995), Ninotchka (1939), Hard Eight (1996), Three Colors: Red (1994), Once Were Warriors (1994), Naked (1993), Total Eclipse (1995), Three Colors: White (1994), Pather Panchali (1955)]                                                                                       |\n",
            "|7      |[Paradise Lost: The Child Murders at Robin Hood Hills (1996), Dangerous Beauty (1998), Little Princess, The (1939), Angel Baby (1995), Little Princess, A (1995), Love! Valour! Compassion! (1997), Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970), Safe (1995), Schizopolis (1996), Schindler's List (1993)]|\n",
            "|8      |[Cats Don't Dance (1997), Bread and Chocolate (Pane e cioccolata) (1973), Judgment Night (1993), Love & Human Remains (1993), I'll Do Anything (1994), Balto (1995), Selena (1997), Addiction, The (1995), Forbidden Planet (1956), Strawberry and Chocolate (Fresa y chocolate) (1993)]                                           |\n",
            "|9      |[Women, The (1939), Naked (1993), Harlem (1993), Endless Summer 2, The (1994), Love & Human Remains (1993), Funny Face (1957), Inventing the Abbotts (1997), High School High (1996), Highlander III: The Sorcerer (1994), Portrait of a Lady, The (1996)]                                                                         |\n",
            "|10     |[Crooklyn (1994), Haunted World of Edward D. Wood Jr., The (1995), Mina Tannenbaum (1994), Pather Panchali (1955), Fresh (1994), Schindler's List (1993), Beautiful Thing (1996), Mrs. Parker and the Vicious Circle (1994), Paradise Lost: The Child Murders at Robin Hood Hills (1996), Close Shave, A (1995)]                   |\n",
            "|11     |[Beautiful Thing (1996), Crooklyn (1994), Braindead (1992), My Man Godfrey (1936), Band Wagon, The (1953), Mrs. Parker and the Vicious Circle (1994), Haunted World of Edward D. Wood Jr., The (1995), Mis�rables, Les (1995), In the Company of Men (1997), Tango Lesson, The (1997)]                                             |\n",
            "|12     |[Stalker (1979), Schizopolis (1996), Shanghai Triad (Yao a yao yao dao waipo qiao) (1995), Chungking Express (1994), Wings of Desire (1987), Love! Valour! Compassion! (1997), Prophecy, The (1995), Body Parts (1991), Portrait of a Lady, The (1996), Kama Sutra: A Tale of Love (1996)]                                         |\n",
            "|13     |[Stupids, The (1996), Three Caballeros, The (1945), Inspector General, The (1949), Unzipped (1995), Stalingrad (1993), Pollyanna (1960), Ninotchka (1939), Friday (1995), Bringing Up Baby (1938), I'm Not Rappaport (1996)]                                                                                                       |\n",
            "|14     |[Lost in Space (1998), Ruby in Paradise (1993), Bread and Chocolate (Pane e cioccolata) (1973), Crooklyn (1994), Alphaville (1965), Inspector General, The (1949), Grace of My Heart (1996), Little Rascals, The (1994), Boys of St. Vincent, The (1993), Amateur (1994)]                                                          |\n",
            "|15     |[Grace of My Heart (1996), Old Man and the Sea, The (1958), Addiction, The (1995), Poetic Justice (1993), Ponette (1996), War, The (1994), Aparajito (1956), Paths of Glory (1957), Hard Eight (1996), Crooklyn (1994)]                                                                                                            |\n",
            "|16     |[Safe (1995), Women, The (1939), Winter Guest, The (1997), My Crazy Life (Mi vida loca) (1993), Inventing the Abbotts (1997), Love & Human Remains (1993), Warriors of Virtue (1997), C�r�monie, La (1995), Wild Things (1998), Selena (1997)]                                                                                     |\n",
            "|17     |[Crooklyn (1994), Alphaville (1965), Bread and Chocolate (Pane e cioccolata) (1973), One Night Stand (1997), Boys of St. Vincent, The (1993), Stupids, The (1996), Lost in Space (1998), Withnail and I (1987), Three Caballeros, The (1945), Bitter Moon (1992)]                                                                  |\n",
            "|18     |[Angel Baby (1995), Mina Tannenbaum (1994), Live Nude Girls (1995), Big Lebowski, The (1998), Once Were Warriors (1994), Sweet Hereafter, The (1997), Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970), Some Mother's Son (1996), Thin Blue Line, The (1988), Bitter Sugar (Azucar Amargo) (1996)]             |\n",
            "|19     |[Live Nude Girls (1995), Waiting to Exhale (1995), Loaded (1994), Priest (1994), Bhaji on the Beach (1993), Maximum Risk (1996), Cemetery Man (Dellamorte Dellamore) (1994), For Whom the Bell Tolls (1943), Once Were Warriors (1994), Beyond Rangoon (1995)]                                                                     |\n",
            "|20     |[Mixed Nuts (1994), Grace of My Heart (1996), War, The (1994), Little Rascals, The (1994), Friday (1995), Swan Princess, The (1994), First Kid (1996), Hard Rain (1998), Jury Duty (1995), My Man Godfrey (1936)]                                                                                                                  |\n",
            "+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' 9-10 lines of code in total expected but can differ based on your style.\n",
        "For sub-parts of the question (if any), creating different cells of code would be recommended.'''\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "k = 10\n",
        "userRecs = model.recommendForAllUsers(k)\n",
        "recommendations = userRecs.select(\"user_id\", explode(\"recommendations\").alias(\"recommendation\"))\n",
        "recommendations = recommendations.select(\"user_id\", \"recommendation.item_id\")\n",
        "recommendations = recommendations.join(items, on=\"item_id\").select(\"user_id\", \"movie\")\n",
        "recommendations = recommendations.groupBy(\"user_id\").agg(collect_list(\"movie\").alias(\"recommended_movies\"))\n",
        "recommendations.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrXJyVNP2AI"
      },
      "source": [
        "Once you have working code for each cell above, **head over to Gradescope, carefully read the questions, and submit your solution for this Colab**!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}