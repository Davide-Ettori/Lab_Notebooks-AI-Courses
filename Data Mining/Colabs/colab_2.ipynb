{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# CS483 - Colab 2\n",
        "## Frequent Pattern Mining in Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "kcxD8L9ORHZx",
        "outputId": "b929ffdd-433a-4898-b710-9cc4c15686f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab 2 Mascot\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://cdn.dribbble.com/users/222579/screenshots/1654898/stubby-ben-rex-roll.gif\" width=\"150\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "print(\"Colab 2 Mascot\")\n",
        "Image(url='https://cdn.dribbble.com/users/222579/screenshots/1654898/stubby-ben-rex-roll.gif',width=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's set up Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-qHai2252mI",
        "outputId": "b9f7fcb8-2b46-4f05-af52-04f4e5450c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u422-b05-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anafrcL39KZZ",
        "outputId": "4cbf66cf-5955-4cd2-9e00-05e4bf286baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0orRvrc1-545"
      },
      "outputs": [],
      "source": [
        "id='1dhi1F78ssqR8gE6U-AgB80ZW7V_9snX4'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('products.csv')\n",
        "\n",
        "id='1KZBNEaIyMTcsRV817us6uLZgm-Mii8oU'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('order_products__train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will need for this Colab under the \"Files\" tab on the left panel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr-8fK-1lmY0"
      },
      "source": [
        "Let's initialize the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOwtm2l7lePt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "add567b3-e84a-43bd-d419-a5f338bd3e36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-7-03ad07eeace4>:5 ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-03ad07eeace4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-7-03ad07eeace4>:5 "
          ]
        }
      ],
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLNUxP0_8x3"
      },
      "source": [
        "If you run successfully the setup stage, you are ready to work with the **3 Million Instacart Orders** dataset. In case you want to read more about it, check the [official Instacart blog post](https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2) about it, a concise [schema description](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b) of the dataset, and the [download page](https://www.instacart.com/datasets/grocery-shopping-2017).\n",
        "\n",
        "In this Colab, we will be working only with a small training dataset (~131K orders) to perform fast Frequent Pattern Mining with the FP-Growth algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu-e7Ph2_ruG"
      },
      "outputs": [],
      "source": [
        "products = spark.read.csv('products.csv', header=True, inferSchema=True)\n",
        "orders = spark.read.csv('order_products__train.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhxZZRT9syUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1492cf7d-5dd5-468f-dcbf-21f3529dcd25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- aisle_id: string (nullable = true)\n",
            " |-- department_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "products.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VeRYRz2s1pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15847ad-caba-4cd1-abc2-9dc6c36abed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: integer (nullable = true)\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- add_to_cart_order: integer (nullable = true)\n",
            " |-- reordered: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "orders.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5muD_Io59CG"
      },
      "source": [
        "Use the Spark Dataframe API to join 'products' and 'orders', so that you will be able to see the product names in each transaction (and not only their ids).  Then, group by the orders by 'order_id' to obtain one row per basket (i.e., set of products purchased together by one customer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRH4o4p7s7V6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3529ab-01c6-48ae-e693-c51093b47c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-----------------+---------+\n",
            "|order_id|        product_name|add_to_cart_order|reordered|\n",
            "+--------+--------------------+-----------------+---------+\n",
            "|       1|    Bulgarian Yogurt|                1|        1|\n",
            "|       1|Organic 4% Milk F...|                2|        1|\n",
            "|       1|Organic Celery He...|                3|        0|\n",
            "|       1|      Cucumber Kirby|                4|        0|\n",
            "|       1|Lightly Smoked Sa...|                5|        1|\n",
            "|       1|Bag of Organic Ba...|                6|        0|\n",
            "|       1|Organic Hass Avocado|                7|        0|\n",
            "|       1|Organic Whole Str...|                8|        1|\n",
            "|      36|Grated Pecorino R...|                1|        0|\n",
            "|      36|        Spring Water|                2|        1|\n",
            "|      36| Organic Half & Half|                3|        0|\n",
            "|      36|  Super Greens Salad|                4|        1|\n",
            "|      36|Cage Free Extra L...|                5|        1|\n",
            "|      36|Prosciutto, Ameri...|                6|        1|\n",
            "|      36|Organic Garnet Sw...|                7|        1|\n",
            "|      36|           Asparagus|                8|        1|\n",
            "|      38|  Shelled Pistachios|                1|        0|\n",
            "|      38|Organic Biologiqu...|                2|        0|\n",
            "|      38|Organic Raw Unfil...|                3|        0|\n",
            "|      38|Organic Baby Arugula|                4|        1|\n",
            "+--------+--------------------+-----------------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+--------------------+\n",
            "|order_id|            products|\n",
            "+--------+--------------------+\n",
            "|       1|[Bulgarian Yogurt...|\n",
            "|      36|[Grated Pecorino ...|\n",
            "|      38|[Shelled Pistachi...|\n",
            "|      96|[Roasted Turkey, ...|\n",
            "|      98|[Natural Spring W...|\n",
            "|     112|[Fresh Cauliflowe...|\n",
            "|     170|[Asian Chopped Sa...|\n",
            "|     218|[Natural Artisan ...|\n",
            "|     226|[Clementines, Bag...|\n",
            "|     349|[Pure Irish Butte...|\n",
            "|     393|[Shredded Mexican...|\n",
            "|     456|[Chorizo Pork, Pe...|\n",
            "|     473|[Organic Whole Mi...|\n",
            "|     631|[Organic Strawber...|\n",
            "|     719|[Heavy Duty Scrub...|\n",
            "|     762|[Organic Strawber...|\n",
            "|     774|[Ice Cream Variet...|\n",
            "|     844|[Green Beans, Org...|\n",
            "|     878|[Chocolate Mint C...|\n",
            "|     904|[Cup Noodles Chic...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' 2 lines of code expected '''\n",
        "# YOUR CODE HERE\n",
        "order_products = orders.join(products, orders.product_id == products.product_id).select(orders.order_id, products.product_name, orders.add_to_cart_order, orders.reordered)\n",
        "order_products.show()\n",
        "baskets = order_products.groupBy('order_id').agg(collect_list('product_name').alias('products')).sort('order_id')\n",
        "baskets.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(baskets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "c_t4J8Ngfd31",
        "outputId": "010f2bf3-fb62-4c5e-8eb3-5ee579b26f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfHoTLAg6qnM"
      },
      "source": [
        "In this Colab we will explore [MLlib](https://spark.apache.org/mllib/), Apache Spark's scalable machine learning library. Specifically, you can use its implementation of the [FP-Growth](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html#fp-growth) algorithm to perform efficiently Frequent Pattern Mining in Spark.\n",
        "Use the Python example in the documentation, and train a model with\n",
        "\n",
        "```minSupport=0.01``` and ```minConfidence=0.5```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boWgxXNns089"
      },
      "outputs": [],
      "source": [
        "''' 3 lines of code expected '''\n",
        "# YOUR CODE HERE\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "fpGrowth = FPGrowth(itemsCol=\"products\", minSupport=0.01, minConfidence=0.5)\n",
        "model = fpGrowth.fit(baskets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kpTVdfD8UiO"
      },
      "source": [
        "Compute how many frequent itemsets and association rules were generated by running FP-growth alongside visalizing top frequent itemsets and association rules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KYgQ_URunvA",
        "outputId": "e6fc8b27-d3e3-4f6a-eb50-a2c192992580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frequent itemsets: 120\n",
            "+--------------------+-----+\n",
            "|               items| freq|\n",
            "+--------------------+-----+\n",
            "|            [Banana]|18726|\n",
            "|[Bag of Organic B...|15480|\n",
            "|[Organic Strawber...|10894|\n",
            "|[Organic Baby Spi...| 9784|\n",
            "|       [Large Lemon]| 8135|\n",
            "|   [Organic Avocado]| 7409|\n",
            "|[Organic Hass Avo...| 7293|\n",
            "|      [Strawberries]| 6494|\n",
            "|             [Limes]| 6033|\n",
            "|[Organic Raspberr...| 5546|\n",
            "|[Organic Blueberr...| 4966|\n",
            "|[Organic Whole Milk]| 4908|\n",
            "|  [Organic Cucumber]| 4613|\n",
            "|  [Organic Zucchini]| 4589|\n",
            "|[Organic Yellow O...| 4290|\n",
            "|    [Organic Garlic]| 4158|\n",
            "|[Seedless Red Gra...| 4059|\n",
            "|         [Asparagus]| 3868|\n",
            "|[Organic Grape To...| 3823|\n",
            "| [Organic Red Onion]| 3818|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Number of association rules: 0\n",
            "+----------+----------+----------+----+-------+\n",
            "|antecedent|consequent|confidence|lift|support|\n",
            "+----------+----------+----------+----+-------+\n",
            "+----------+----------+----------+----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' 5 lines of code in total expected but can differ based on your style. for sub-parts of the question, creating different cells of code would be recommended.'''\n",
        "# YOUR CODE HERE\n",
        "itemsets = model.freqItemsets\n",
        "print(\"Number of frequent itemsets: \" + str(itemsets.count()))\n",
        "itemsets.orderBy(desc(\"freq\")).show()\n",
        "rules = model.associationRules\n",
        "print(\"Number of association rules: \" + str(rules.count()))\n",
        "rules.orderBy(desc(\"confidence\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT8Lwm1VAPoN"
      },
      "source": [
        "Now retrain the FP-growth model changing only\n",
        "```minsupport=0.001```\n",
        "and compute how many frequent itemsets and association rules were generated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4LTM9beApYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19cc12b0-47c6-41fe-bfda-9226d6c83b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frequent itemsets: 4444\n",
            "+--------------------+-----+\n",
            "|               items| freq|\n",
            "+--------------------+-----+\n",
            "|            [Banana]|18726|\n",
            "|[Bag of Organic B...|15480|\n",
            "|[Organic Strawber...|10894|\n",
            "|[Organic Baby Spi...| 9784|\n",
            "|       [Large Lemon]| 8135|\n",
            "|   [Organic Avocado]| 7409|\n",
            "|[Organic Hass Avo...| 7293|\n",
            "|      [Strawberries]| 6494|\n",
            "|             [Limes]| 6033|\n",
            "|[Organic Raspberr...| 5546|\n",
            "|[Organic Blueberr...| 4966|\n",
            "|[Organic Whole Milk]| 4908|\n",
            "|  [Organic Cucumber]| 4613|\n",
            "|  [Organic Zucchini]| 4589|\n",
            "|[Organic Yellow O...| 4290|\n",
            "|    [Organic Garlic]| 4158|\n",
            "|[Seedless Red Gra...| 4059|\n",
            "|         [Asparagus]| 3868|\n",
            "|[Organic Grape To...| 3823|\n",
            "| [Organic Red Onion]| 3818|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Number of association rules: 11\n",
            "+--------------------+--------------------+------------------+------------------+--------------------+\n",
            "|          antecedent|          consequent|        confidence|              lift|             support|\n",
            "+--------------------+--------------------+------------------+------------------+--------------------+\n",
            "|[Organic Raspberr...|[Bag of Organic B...|0.5984251968503937| 5.072272070642333|0.001737685677049...|\n",
            "|[Organic Cucumber...|[Bag of Organic B...|          0.546875| 4.635330870478036|0.001066999977135...|\n",
            "|[Organic Kiwi, Or...|[Bag of Organic B...|0.5459770114942529| 4.627719489738336|0.001448071397541327|\n",
            "|[Organic Navel Or...|[Bag of Organic B...|0.5412186379928315| 4.587387356098284|0.001150835689624...|\n",
            "|[Yellow Onions, S...|            [Banana]|0.5357142857142857|3.7536332219526702|0.001143214261216...|\n",
            "|[Organic Whole St...|[Bag of Organic B...|0.5314685314685315| 4.504745125675359|0.001158457118033...|\n",
            "|[Organic Navel Or...|[Bag of Organic B...|0.5283018867924528| 4.477904539027839|0.001493799967990...|\n",
            "|[Organic Raspberr...|[Bag of Organic B...| 0.521099116781158| 4.416853618458589|0.004046978484707604|\n",
            "|[Organic D'Anjou ...|[Bag of Organic B...|0.5170454545454546|4.3824946411792345|0.001387099970276...|\n",
            "|[Organic Unsweete...|[Bag of Organic B...|0.5141065830721003| 4.357584667849303|0.001249914258930...|\n",
            "|[Organic Broccoli...|[Bag of Organic B...|0.5048231511254019| 4.278897986822536|0.001196564260073623|\n",
            "+--------------------+--------------------+------------------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' 5 lines of code in total expected but can differ based on your style. for sub-parts of the question, creating different cells of code would be recommended.'''\n",
        "# YOUR CODE HERE\n",
        "fpGrowth = FPGrowth(itemsCol=\"products\", minSupport=0.001, minConfidence=0.5)\n",
        "model = fpGrowth.fit(baskets)\n",
        "\n",
        "itemsets = model.freqItemsets\n",
        "print(\"Number of frequent itemsets: \" + str(itemsets.count()))\n",
        "itemsets.orderBy(desc(\"freq\")).show()\n",
        "\n",
        "rules = model.associationRules\n",
        "print(\"Number of association rules: \" + str(rules.count()))\n",
        "rules.orderBy(desc(\"confidence\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9FOt5jRNFGt"
      },
      "source": [
        "To conclude, go to Gradescope and read the remaining questions. We will ask you to inspect the resulting dataframes, and report a few results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEqWxzTCNS87"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WSXPflUN76-"
      },
      "source": [
        "Once you obtained the desired results, **head over to Gradescope and submit your solution for this Colab**!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}