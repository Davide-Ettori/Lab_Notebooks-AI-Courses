{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b7938b-f42b-4f2d-9780-ee73a36bf60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/06 15:22:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/06 15:22:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/12/06 15:22:54 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'], os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable, sys.executable\n",
    "\n",
    "# Import the basic spark library\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"spark_tutorial\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148cdf03-a8fa-42c7-b113-c4b206f213d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pizza Name: string (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- Ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+---------------------------------------------------+\n",
      "|Pizza Name     |Price|Ingredients                                        |\n",
      "+---------------+-----+---------------------------------------------------+\n",
      "|Margherita     |5.95 |[Tomato Sauce, Mozzarella Cheese, Basil]           |\n",
      "|Calzone        |7.95 |[Tomato Sauce, Mozzarella Cheese, Prosciutto Cotto]|\n",
      "|Diavola        |5.95 |[Tomato Sauce, Mozzarella Cheese, Spicy Salame]    |\n",
      "|Prosciutto     |7.95 |[Tomato Sauce, Mozzarella Cheese, Prosciutto Cotto]|\n",
      "|Speck & Brie   |7.95 |[Tomato Sauce, Mozzarella Cheese, Speck, Brie]     |\n",
      "|Tonno & Cipolle|7.95 |[Tomato Sauce, Mozzarella Cheese, Tuna, Onions]    |\n",
      "|Fries          |3.95 |[Potatoes]                                         |\n",
      "+---------------+-----+---------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "\n",
    "#Createe the schema using StructField(Name, Type, Nullable)\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Pizza Name\", StringType(), True), \\\n",
    "    StructField(\"Price\", FloatType(), True), \\\n",
    "    StructField(\"Ingredients\", ArrayType(StringType()), True) \\\n",
    "])\n",
    "\n",
    "df_data = [(\"Margherita\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Basil\"]),\n",
    "        (\"Calzone\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Diavola\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Spicy Salame\"]),\n",
    "        (\"Prosciutto\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Speck & Brie\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Speck\", \"Brie\"]),\n",
    "        (\"Tonno & Cipolle\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Tuna\", \"Onions\"]),\n",
    "        (\"Fries\", 3.95, [\"Potatoes\"])]\n",
    "\n",
    "df = spark.createDataFrame(data = df_data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7401b-38e2-4fbf-a69e-e34fcfadc764",
   "metadata": {},
   "source": [
    "<h4>Grouping using groupBy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c275c5-89d1-4fd4-911a-08f5874b38dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Price|count|\n",
      "+-----+-----+\n",
      "|7.95 |4    |\n",
      "|3.95 |1    |\n",
      "|5.95 |2    |\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count\n",
    "df.groupBy(\"Price\").count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a0a4a7-3260-4ac1-a83e-9db36932d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(Price)|\n",
      "+----------+\n",
      "|3.95      |\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum\n",
    "df.groupBy().min(\"Price\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbcf3b8-5b76-432f-828e-f5ea9fbf3e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg(Price)       |\n",
      "+-----------------+\n",
      "|6.807142700467791|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average\n",
    "df.groupBy().avg(\"Price\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2559e-ef28-42c3-bbf8-06e0e9671679",
   "metadata": {},
   "source": [
    "<h4>Grouping Multiple Columns</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dda12b6-64ca-4765-ab55-c46e9d4f2eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pizza Name: string (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- Ingredient: string (nullable = true)\n",
      "\n",
      "+---------------+-----+-----------------+\n",
      "|Pizza Name     |Price|Ingredient       |\n",
      "+---------------+-----+-----------------+\n",
      "|Margherita     |5.95 |Tomato Sauce     |\n",
      "|Margherita     |5.95 |Mozzarella Cheese|\n",
      "|Margherita     |5.95 |Basil            |\n",
      "|Calzone        |7.95 |Tomato Sauce     |\n",
      "|Calzone        |7.95 |Mozzarella Cheese|\n",
      "|Calzone        |7.95 |Prosciutto Cotto |\n",
      "|Diavola        |5.95 |Tomato Sauce     |\n",
      "|Diavola        |5.95 |Mozzarella Cheese|\n",
      "|Diavola        |5.95 |Spicy Salame     |\n",
      "|Prosciutto     |7.95 |Tomato Sauce     |\n",
      "|Prosciutto     |7.95 |Mozzarella Cheese|\n",
      "|Prosciutto     |7.95 |Prosciutto Cotto |\n",
      "|Speck & Brie   |7.95 |Tomato Sauce     |\n",
      "|Speck & Brie   |7.95 |Mozzarella Cheese|\n",
      "|Speck & Brie   |7.95 |Speck            |\n",
      "|Speck & Brie   |7.95 |Brie             |\n",
      "|Tonno & Cipolle|7.95 |Tomato Sauce     |\n",
      "|Tonno & Cipolle|7.95 |Mozzarella Cheese|\n",
      "|Tonno & Cipolle|7.95 |Tuna             |\n",
      "|Tonno & Cipolle|7.95 |Onions           |\n",
      "+---------------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's explode our array to perform more interesting operations\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "exploded_df = df.select(col(\"Pizza Name\"), df.Price, explode(df.Ingredients))\n",
    "exploded_df = exploded_df.withColumnRenamed(\"col\", \"Ingredient\")\n",
    "exploded_df.printSchema()\n",
    "exploded_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a836aa71-43c1-432f-a265-480b594bdacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+-----+\n",
      "|Ingredient       |Price|count|\n",
      "+-----------------+-----+-----+\n",
      "|Prosciutto Cotto |7.95 |2    |\n",
      "|Basil            |5.95 |1    |\n",
      "|Mozzarella Cheese|7.95 |4    |\n",
      "|Tomato Sauce     |7.95 |4    |\n",
      "|Tuna             |7.95 |1    |\n",
      "|Speck            |7.95 |1    |\n",
      "|Brie             |7.95 |1    |\n",
      "|Mozzarella Cheese|5.95 |2    |\n",
      "|Tomato Sauce     |5.95 |2    |\n",
      "|Spicy Salame     |5.95 |1    |\n",
      "|Onions           |7.95 |1    |\n",
      "|Potatoes         |3.95 |1    |\n",
      "+-----------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting\n",
    "exploded_df.groupBy(\"Ingredient\", \"Price\").count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc6d797-6e92-476b-adc8-69a498e5f018",
   "metadata": {},
   "source": [
    "<h4>Multiple Aggregations</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8447a1-ba9b-4032-8e48-522fda2c3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-----------------+---------------------+-----+\n",
      "|Pizza Name     |Sum Price         |Average Price    |Number of Ingredients|Price|\n",
      "+---------------+------------------+-----------------+---------------------+-----+\n",
      "|Calzone        |23.84999942779541 |7.949999809265137|3                    |7.95 |\n",
      "|Diavola        |17.84999942779541 |5.949999809265137|3                    |5.95 |\n",
      "|Fries          |3.950000047683716 |3.950000047683716|1                    |3.95 |\n",
      "|Prosciutto     |23.84999942779541 |7.949999809265137|3                    |7.95 |\n",
      "|Margherita     |17.84999942779541 |5.949999809265137|3                    |5.95 |\n",
      "|Speck & Brie   |31.799999237060547|7.949999809265137|4                    |7.95 |\n",
      "|Tonno & Cipolle|31.799999237060547|7.949999809265137|4                    |7.95 |\n",
      "+---------------+------------------+-----------------+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, avg, count, max\n",
    "\n",
    "exploded_df.groupBy(\"Pizza Name\").agg(\n",
    "    sum(\"Price\").alias(\"Sum Price\"),\n",
    "    avg(\"Price\").alias(\"Average Price\"),\n",
    "    count(\"Ingredient\").alias(\"Number of Ingredients\"),\n",
    "    max(\"Price\").alias(\"Price\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7941ed75-a2c3-413b-a6b2-22339a15d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|Pizza Name     |Number of Ingredients|\n",
      "+---------------+---------------------+\n",
      "|Speck & Brie   |4                    |\n",
      "|Tonno & Cipolle|4                    |\n",
      "+---------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's keep only the Pizza's with at least four ingredients\n",
    "exploded_df.groupBy(\"Pizza Name\") \\\n",
    "    .agg(count(\"Ingredient\").alias(\"Number of Ingredients\")) \\\n",
    "    .filter(col(\"Number of Ingredients\") >= 4) \\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8fc369-a1ba-4358-9c27-e5c7cb732fb7",
   "metadata": {},
   "source": [
    "<h4>Aggregate Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de799bee-1ead-4e71-bc97-b3b29a090066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/06 15:31:29 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "Number of different ingredients 10\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "# Count the number of unique values in a field\n",
    "print(\"Number of different ingredients\", str(exploded_df.select(approx_count_distinct(\"Ingredient\")).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd0014a-5a6e-4e13-9a04-1bdaa082eccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Price:  6.807142700467791\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Compute the average price for a Pizza\n",
    "print(\"Average Price: \", str(df.select(avg(\"Price\")).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "535e3904-3343-4a43-846f-e5ca70c65326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tomato Sauce',\n",
       " 'Mozzarella Cheese',\n",
       " 'Basil',\n",
       " 'Tomato Sauce',\n",
       " 'Mozzarella Cheese',\n",
       " 'Prosciutto Cotto',\n",
       " 'Tomato Sauce',\n",
       " 'Mozzarella Cheese',\n",
       " 'Spicy Salame',\n",
       " 'Tomato Sauce',\n",
       " 'Mozzarella Cheese',\n",
       " 'Prosciutto Cotto',\n",
       " 'Tomato Sauce',\n",
       " 'Mozzarella Cheese',\n",
       " 'Speck',\n",
       " 'Brie',\n",
       " 'Tomato Sauce',\n",
       " 'Mozzarella Cheese',\n",
       " 'Tuna',\n",
       " 'Onions',\n",
       " 'Potatoes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "# Return all the values from a column (with duplicates)\n",
    "exploded_df.select(collect_list(\"Ingredient\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713d37e1-8a76-4f43-a10a-f512c38404a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|collect_list(Ingredient)                                                                                                                                                                                                                                                                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Tomato Sauce, Mozzarella Cheese, Basil, Tomato Sauce, Mozzarella Cheese, Prosciutto Cotto, Tomato Sauce, Mozzarella Cheese, Spicy Salame, Tomato Sauce, Mozzarella Cheese, Prosciutto Cotto, Tomato Sauce, Mozzarella Cheese, Speck, Brie, Tomato Sauce, Mozzarella Cheese, Tuna, Onions, Potatoes]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df.select(collect_list(\"Ingredient\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5899f365-ef66-4925-baf4-d0eddfe5ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basil',\n",
       " 'Tuna',\n",
       " 'Mozzarella Cheese',\n",
       " 'Brie',\n",
       " 'Onions',\n",
       " 'Speck',\n",
       " 'Prosciutto Cotto',\n",
       " 'Tomato Sauce',\n",
       " 'Potatoes',\n",
       " 'Spicy Salame']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "# Return all the values from a column (without duplicates)\n",
    "exploded_df.select(collect_set(\"Ingredient\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8464cc71-74df-4f36-9ffc-2f3635d0dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|12   |\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Return all the values from a column (without duplicates)\n",
    "exploded_df.select(countDistinct(\"Ingredient\", \"Price\")).withColumnRenamed(\"count(DISTINCT Ingredient, Price)\", \"count\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb82ff1f-8d7a-452b-b40b-ef115c8369ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|first(Ingredients)                      |\n",
      "+----------------------------------------+\n",
      "|[Tomato Sauce, Mozzarella Cheese, Basil]|\n",
      "+----------------------------------------+\n",
      "\n",
      "+-----------------+\n",
      "|last(Ingredients)|\n",
      "+-----------------+\n",
      "|[Potatoes]       |\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "\n",
    "# Select the first non-null element of the column\n",
    "df.select(first(\"Ingredients\")).show(truncate = False)\n",
    "\n",
    "# Select the last non-null element of the column\n",
    "df.select(last(\"Ingredients\")).show(truncate = False)\n",
    "\n",
    "# A wide variety of functions is also available, like avg(), sum(), mean(), variance(), stddev(), etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
